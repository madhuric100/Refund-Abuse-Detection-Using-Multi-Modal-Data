{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94b7091-88f5-4a21-b6ca-360dc92cb222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully.\n",
      "\n",
      "--- Sample Customer Retail Summary (Structured Features) ---\n",
      "   CustomerID  TotalUniqueOrders  TotalItemsPurchased  TotalItemsReturned  \\\n",
      "0       12346                  2                74215               74215   \n",
      "1       12347                  7                 2458                   0   \n",
      "2       12348                  4                 2341                   0   \n",
      "3       12349                  1                  631                   0   \n",
      "4       12350                  1                  197                   0   \n",
      "\n",
      "   TotalPurchaseValue  TotalRefundValue FirstTransactionDate  \\\n",
      "0            77183.60           77183.6  2011-01-18 10:01:00   \n",
      "1             4310.00               0.0  2010-12-07 14:57:00   \n",
      "2             1797.24               0.0  2010-12-16 19:09:00   \n",
      "3             1757.55               0.0  2011-11-21 09:51:00   \n",
      "4              334.40               0.0  2011-02-02 16:01:00   \n",
      "\n",
      "  LastTransactionDate  RefundRate_by_Items  RefundRate_by_Value  \\\n",
      "0 2011-01-18 10:17:00                  1.0                  1.0   \n",
      "1 2011-12-07 15:52:00                  0.0                  0.0   \n",
      "2 2011-09-25 13:13:00                  0.0                  0.0   \n",
      "3 2011-11-21 09:51:00                  0.0                  0.0   \n",
      "4 2011-02-02 16:01:00                  0.0                  0.0   \n",
      "\n",
      "   AccountAgeDays  \n",
      "0               0  \n",
      "1             365  \n",
      "2             282  \n",
      "3               0  \n",
      "4               0  \n",
      "\n",
      "--- Sample Tickets with Simulated CustomerID ---\n",
      "               Customer Email  Simulated_CustomerID      Ticket Type  \\\n",
      "0  carrollallison@example.com                 13489  Technical issue   \n",
      "1    clarkeashley@example.com                 17466  Technical issue   \n",
      "2   gonzalestracy@example.com                 16527  Technical issue   \n",
      "3    bradleyolson@example.org                 12942  Billing inquiry   \n",
      "4     bradleymark@example.com                 17007  Billing inquiry   \n",
      "\n",
      "                                  Ticket Description  \n",
      "0  I'm having an issue with the {product_purchase...  \n",
      "1  I'm having an issue with the {product_purchase...  \n",
      "2  I'm facing a problem with my {product_purchase...  \n",
      "3  I'm having an issue with the {product_purchase...  \n",
      "4  I'm having an issue with the {product_purchase...  \n",
      "\n",
      "--- Sample Customer Ticket Summary (NLP-Derived Features) ---\n",
      "   Simulated_CustomerID  TotalTickets  Tickets_TypeRefundRequest  \\\n",
      "0                 12347             3                          1   \n",
      "1                 12348             3                          1   \n",
      "2                 12349             1                          0   \n",
      "3                 12350             2                          2   \n",
      "4                 12352             1                          1   \n",
      "\n",
      "   Tickets_TypeDeliveryIssue  Tickets_TypeProductInquiry  \\\n",
      "0                          0                           1   \n",
      "1                          0                           0   \n",
      "2                          0                           0   \n",
      "3                          0                           0   \n",
      "4                          0                           0   \n",
      "\n",
      "   Tickets_KeywordRefundCount  Tickets_KeywordDamageCount  \\\n",
      "0                           0                           1   \n",
      "1                           0                           0   \n",
      "2                           0                           0   \n",
      "3                           1                           0   \n",
      "4                           0                           0   \n",
      "\n",
      "   Tickets_KeywordMissingCount  AvgTicketSentimentScore  \\\n",
      "0                            0                -0.777778   \n",
      "1                            0                -1.000000   \n",
      "2                            0                -0.333333   \n",
      "3                            0                -1.000000   \n",
      "4                            0                -1.000000   \n",
      "\n",
      "   MinTicketSentimentScore  \n",
      "0                -1.000000  \n",
      "1                -1.000000  \n",
      "2                -0.333333  \n",
      "3                -1.000000  \n",
      "4                -1.000000  \n",
      "\n",
      "--- Sample of Final Combined Multi-Modal Dataset ---\n",
      "   Simulated_CustomerID  TotalItemsPurchased  TotalItemsReturned  \\\n",
      "0                 12346                74215               74215   \n",
      "1                 12347                 2458                   0   \n",
      "2                 12348                 2341                   0   \n",
      "3                 12349                  631                   0   \n",
      "4                 12350                  197                   0   \n",
      "\n",
      "   RefundRate_by_Items  RefundRate_by_Value  TotalTickets  \\\n",
      "0                  1.0                  1.0           0.0   \n",
      "1                  0.0                  0.0           3.0   \n",
      "2                  0.0                  0.0           3.0   \n",
      "3                  0.0                  0.0           1.0   \n",
      "4                  0.0                  0.0           2.0   \n",
      "\n",
      "   Tickets_TypeRefundRequest  Tickets_KeywordMissingCount  \\\n",
      "0                        0.0                          0.0   \n",
      "1                        1.0                          0.0   \n",
      "2                        1.0                          0.0   \n",
      "3                        0.0                          0.0   \n",
      "4                        2.0                          0.0   \n",
      "\n",
      "   AvgTicketSentimentScore  is_refund_abuser  \n",
      "0                 0.000000                 0  \n",
      "1                -0.777778                 0  \n",
      "2                -1.000000                 0  \n",
      "3                -0.333333                 0  \n",
      "4                -1.000000                 0  \n",
      "\n",
      "Total customers in combined dataset: 4372\n",
      "Number of simulated refund abusers: 769\n",
      "\n",
      "--- Distribution of 'is_refund_abuser' ---\n",
      "is_refund_abuser\n",
      "0    3603\n",
      "1     769\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Proportion of 'is_refund_abuser' ---\n",
      "is_refund_abuser\n",
      "0    0.824108\n",
      "1    0.175892\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # For regular expressions in NLP-like tasks\n",
    "\n",
    "# --- 1. Load Datasets ---\n",
    "try:\n",
    "    # OnlineRetail.csv often requires 'ISO-8859-1' encoding\n",
    "    df_retail = pd.read_csv('OnlineRetail.csv', encoding='ISO-8859-1')\n",
    "    df_tickets = pd.read_csv('customer_support_tickets.csv')\n",
    "    print(\"Datasets loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"One or more files not found. Please ensure 'OnlineRetail.csv' and 'customer_support_tickets.csv' are uploaded.\")\n",
    "    # Exit or handle the error appropriately if files are missing\n",
    "    exit()\n",
    "\n",
    "# --- 2. Preprocessing for OnlineRetail.csv (Structured Data) ---\n",
    "\n",
    "# Drop rows with missing CustomerID as they cannot be linked to customer behavior\n",
    "# In a real scenario, you might try to impute or link via other means if available.\n",
    "df_retail.dropna(subset=['CustomerID'], inplace=True)\n",
    "df_retail['CustomerID'] = df_retail['CustomerID'].astype(int) # Convert CustomerID to integer\n",
    "\n",
    "# Convert InvoiceDate to datetime objects for time-based analysis\n",
    "df_retail['InvoiceDate'] = pd.to_datetime(df_retail['InvoiceDate'])\n",
    "\n",
    "# Identify returns.\n",
    "# Transactions with InvoiceNo starting with 'C' explicitly denote a cancellation/return.\n",
    "# Negative quantity also indicates a return. We'll use both for robustness.\n",
    "df_retail['IsReturn'] = df_retail['InvoiceNo'].astype(str).str.startswith('C') | (df_retail['Quantity'] < 0)\n",
    "\n",
    "# Calculate the actual quantity for purchases and absolute quantity for returns\n",
    "df_retail['PurchaseQuantity'] = df_retail['Quantity'].apply(lambda x: x if x > 0 else 0)\n",
    "df_retail['ReturnQuantity'] = df_retail['Quantity'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "\n",
    "# Calculate line total (positive for purchases, negative for returns)\n",
    "df_retail['LineTotal'] = df_retail['Quantity'] * df_retail['UnitPrice']\n",
    "\n",
    "# --- 3. Feature Engineering for OnlineRetail.csv (Customer-level Structured Features) ---\n",
    "\n",
    "# Aggregate retail data to customer level\n",
    "customer_retail_summary = df_retail.groupby('CustomerID').agg(\n",
    "    TotalUniqueOrders=('InvoiceNo', 'nunique'),\n",
    "    TotalItemsPurchased=('PurchaseQuantity', 'sum'),\n",
    "    TotalItemsReturned=('ReturnQuantity', 'sum'),\n",
    "    TotalPurchaseValue=('LineTotal', lambda x: x[x > 0].sum()), # Sum of positive LineTotal\n",
    "    TotalRefundValue=('LineTotal', lambda x: x[x < 0].abs().sum()), # Sum of absolute negative LineTotal\n",
    "    FirstTransactionDate=('InvoiceDate', 'min'),\n",
    "    LastTransactionDate=('InvoiceDate', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate derived features for each customer\n",
    "# Avoid division by zero by replacing 0 with NaN for division, then filling NaN with 0\n",
    "customer_retail_summary['RefundRate_by_Items'] = customer_retail_summary['TotalItemsReturned'] / customer_retail_summary['TotalItemsPurchased'].replace(0, np.nan)\n",
    "customer_retail_summary['RefundRate_by_Items'].fillna(0, inplace=True)\n",
    "\n",
    "customer_retail_summary['RefundRate_by_Value'] = customer_retail_summary['TotalRefundValue'] / customer_retail_summary['TotalPurchaseValue'].replace(0, np.nan)\n",
    "customer_retail_summary['RefundRate_by_Value'].fillna(0, inplace=True)\n",
    "\n",
    "# Age of customer account based on their first and last transaction\n",
    "customer_retail_summary['AccountAgeDays'] = (customer_retail_summary['LastTransactionDate'] - customer_retail_summary['FirstTransactionDate']).dt.days.fillna(0)\n",
    "\n",
    "print(\"\\n--- Sample Customer Retail Summary (Structured Features) ---\")\n",
    "print(customer_retail_summary.head())\n",
    "\n",
    "# --- 4. Preprocessing for customer_support_tickets.csv (Unstructured Data) ---\n",
    "\n",
    "# Convert 'Date of Purchase' to datetime if needed for any time-based linkage\n",
    "df_tickets['Date of Purchase'] = pd.to_datetime(df_tickets['Date of Purchase'])\n",
    "\n",
    "# Ensure Ticket Description is string type and fill any potential NaNs\n",
    "df_tickets['Ticket Description'] = df_tickets['Ticket Description'].astype(str).fillna('')\n",
    "\n",
    "# --- 5. Simulated CustomerID Mapping for Linking ---\n",
    "# This is a crucial step to bridge the two datasets.\n",
    "# In a real application, you'd use a single, universal CustomerID present in both systems.\n",
    "# Here, we simulate a linkage by mapping ticket emails to existing retail CustomerIDs.\n",
    "# This approach is illustrative and its effectiveness depends on the overlap and distribution\n",
    "# of customer identifiers in a real scenario.\n",
    "\n",
    "unique_retail_customers = customer_retail_summary['CustomerID'].unique()\n",
    "unique_ticket_emails = df_tickets['Customer Email'].unique()\n",
    "\n",
    "# Create a random mapping from ticket emails to a subset of retail customer IDs\n",
    "# This is purely for demonstration purposes to create a joinable key.\n",
    "# In a real scenario, this would be a direct link from your database.\n",
    "np.random.seed(42) # For reproducibility of random assignments\n",
    "\n",
    "# Ensure there are enough retail customer IDs to map to ticket emails\n",
    "if len(unique_retail_customers) == 0:\n",
    "    print(\"No valid CustomerIDs found in OnlineRetail.csv after preprocessing. Cannot simulate linkage.\")\n",
    "    exit()\n",
    "\n",
    "# Map a random retail CustomerID to each unique ticket email\n",
    "email_to_simulated_customer_id_map = {\n",
    "    email: np.random.choice(unique_retail_customers)\n",
    "    for email in unique_ticket_emails\n",
    "}\n",
    "\n",
    "df_tickets['Simulated_CustomerID'] = df_tickets['Customer Email'].map(email_to_simulated_customer_id_map)\n",
    "\n",
    "# Drop tickets that couldn't be mapped (e.g., if an email wasn't in our simulated map, though unlikely here)\n",
    "df_tickets.dropna(subset=['Simulated_CustomerID'], inplace=True)\n",
    "df_tickets['Simulated_CustomerID'] = df_tickets['Simulated_CustomerID'].astype(int)\n",
    "\n",
    "print(\"\\n--- Sample Tickets with Simulated CustomerID ---\")\n",
    "print(df_tickets[['Customer Email', 'Simulated_CustomerID', 'Ticket Type', 'Ticket Description']].head())\n",
    "\n",
    "\n",
    "# --- 6. Feature Engineering for customer_support_tickets.csv (NLP Features) ---\n",
    "\n",
    "# Simple NLP simulation: Keyword detection and very basic sentiment approximation\n",
    "# (More advanced NLP would use libraries like NLTK, spaCy, or Hugging Face Transformers)\n",
    "\n",
    "# Keywords often associated with refund abuse or problematic claims\n",
    "refund_keywords = ['refund', 'return', 'cancel', 'money back', 'send back', 'credit']\n",
    "damage_keywords = ['damaged', 'broken', 'faulty', 'defective', 'not working', 'malfunction']\n",
    "missing_keywords = ['missing', 'never arrived', 'lost package', 'not received', 'where is my order']\n",
    "negative_sentiment_terms = ['bad', 'poor', 'unhappy', 'frustrated', 'terrible', 'issue', 'problem', 'unresolved']\n",
    "positive_sentiment_terms = ['happy', 'satisfied', 'resolved', 'excellent', 'great', 'thank you']\n",
    "\n",
    "def count_keywords(text, keywords_list):\n",
    "    # Use re.IGNORECASE for case-insensitive matching\n",
    "    # Use word boundaries (\\b) to match whole words\n",
    "    count = 0\n",
    "    for keyword in keywords_list:\n",
    "        count += len(re.findall(r'\\b' + re.escape(keyword) + r'\\b', text.lower()))\n",
    "    return count\n",
    "\n",
    "def get_basic_sentiment_score(text):\n",
    "    text_lower = text.lower()\n",
    "    pos_count = count_keywords(text_lower, positive_sentiment_terms)\n",
    "    neg_count = count_keywords(text_lower, negative_sentiment_terms)\n",
    "\n",
    "    if (pos_count + neg_count) == 0:\n",
    "        return 0 # Neutral if no sentiment words found\n",
    "    return (pos_count - neg_count) / (pos_count + neg_count) # Simple score -1 to 1\n",
    "\n",
    "df_tickets['Keywords_RefundCount'] = df_tickets['Ticket Description'].apply(lambda x: count_keywords(x, refund_keywords))\n",
    "df_tickets['Keywords_DamageCount'] = df_tickets['Ticket Description'].apply(lambda x: count_keywords(x, damage_keywords))\n",
    "df_tickets['Keywords_MissingCount'] = df_tickets['Ticket Description'].apply(lambda x: count_keywords(x, missing_keywords))\n",
    "df_tickets['TicketSentimentScore'] = df_tickets['Ticket Description'].apply(get_basic_sentiment_score)\n",
    "\n",
    "# Aggregate NLP features per simulated CustomerID\n",
    "customer_ticket_summary = df_tickets.groupby('Simulated_CustomerID').agg(\n",
    "    TotalTickets=('Ticket ID', 'count'),\n",
    "    Tickets_TypeRefundRequest=('Ticket Type', lambda x: (x == 'Refund request').sum()),\n",
    "    Tickets_TypeDeliveryIssue=('Ticket Type', lambda x: (x == 'Delivery issue').sum()),\n",
    "    Tickets_TypeProductInquiry=('Ticket Type', lambda x: (x == 'Product inquiry').sum()),\n",
    "    Tickets_KeywordRefundCount=('Keywords_RefundCount', 'sum'),\n",
    "    Tickets_KeywordDamageCount=('Keywords_DamageCount', 'sum'),\n",
    "    Tickets_KeywordMissingCount=('Keywords_MissingCount', 'sum'),\n",
    "    AvgTicketSentimentScore=('TicketSentimentScore', 'mean'),\n",
    "    MinTicketSentimentScore=('TicketSentimentScore', 'min') # Min score might indicate most negative interaction\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\n--- Sample Customer Ticket Summary (NLP-Derived Features) ---\")\n",
    "print(customer_ticket_summary.head())\n",
    "\n",
    "# --- 7. Combine the Features ---\n",
    "# Merge structured features with NLP-derived features on the Simulated_CustomerID\n",
    "\n",
    "# Rename CustomerID in retail summary to match for merge\n",
    "customer_retail_summary.rename(columns={'CustomerID': 'Simulated_CustomerID'}, inplace=True)\n",
    "\n",
    "final_combined_df = pd.merge(\n",
    "    customer_retail_summary,\n",
    "    customer_ticket_summary,\n",
    "    on='Simulated_CustomerID',\n",
    "    how='left' # Keep all customers from retail summary, add ticket data if available\n",
    ")\n",
    "\n",
    "# Fill NaN values for customers who have no corresponding tickets in our simulated linkage\n",
    "# These NaNs result from the 'left' merge when a retail customer has no mapped tickets.\n",
    "final_combined_df.fillna({\n",
    "    'TotalTickets': 0,\n",
    "    'Tickets_TypeRefundRequest': 0,\n",
    "    'Tickets_TypeDeliveryIssue': 0,\n",
    "    'Tickets_TypeProductInquiry': 0,\n",
    "    'Tickets_KeywordRefundCount': 0,\n",
    "    'Tickets_KeywordDamageCount': 0,\n",
    "    'Tickets_KeywordMissingCount': 0,\n",
    "    'AvgTicketSentimentScore': 0, # Assume neutral sentiment if no tickets\n",
    "    'MinTicketSentimentScore': 0  # Assume neutral sentiment if no tickets\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# --- 8. Define a Conceptual Target Variable (`is_refund_abuser`) ---\n",
    "# This is a simplified heuristic for demonstration purposes ONLY.\n",
    "# In a real scenario, this would be based on detailed business rules,\n",
    "# confirmed fraud labels, or expert review.\n",
    "\n",
    "# Heuristic criteria for 'is_refund_abuser':\n",
    "# A customer is flagged as a potential refund abuser if:\n",
    "# (Condition A) High Refund Rate (by items) AND multiple explicit Refund Request tickets\n",
    "# OR\n",
    "# (Condition B) Moderately high Refund Rate (by value) AND high counts of missing/damage keywords in tickets\n",
    "# OR\n",
    "# (Condition C) Very low (negative) average sentiment score AND a high number of items returned\n",
    "\n",
    "final_combined_df['is_refund_abuser'] = (\n",
    "    (final_combined_df['RefundRate_by_Items'] > 0.3) & # E.g., more than 30% of items returned\n",
    "    (final_combined_df['Tickets_TypeRefundRequest'] >= 2) # At least 2 explicit refund request tickets\n",
    ") | (\n",
    "    (final_combined_df['RefundRate_by_Value'] > 0.2) & # E.g., more than 20% value refunded\n",
    "    ( (final_combined_df['Tickets_KeywordMissingCount'] > 0) | (final_combined_df['Tickets_KeywordDamageCount'] > 0) ) # Has tickets with missing or damage claims\n",
    ") | (\n",
    "    (final_combined_df['MinTicketSentimentScore'] < -0.5) & # At least one very negative interaction\n",
    "    (final_combined_df['TotalItemsReturned'] > 5) # And a significant number of items returned\n",
    ")\n",
    "\n",
    "\n",
    "# Convert boolean target variable to integer (0 for legitimate, 1 for abuser)\n",
    "final_combined_df['is_refund_abuser'] = final_combined_df['is_refund_abuser'].astype(int)\n",
    "\n",
    "print(\"\\n--- Sample of Final Combined Multi-Modal Dataset ---\")\n",
    "print(final_combined_df[['Simulated_CustomerID', 'TotalItemsPurchased', 'TotalItemsReturned',\n",
    "                         'RefundRate_by_Items', 'RefundRate_by_Value', 'TotalTickets',\n",
    "                         'Tickets_TypeRefundRequest', 'Tickets_KeywordMissingCount',\n",
    "                         'AvgTicketSentimentScore', 'is_refund_abuser']].head())\n",
    "print(f\"\\nTotal customers in combined dataset: {len(final_combined_df)}\")\n",
    "print(f\"Number of simulated refund abusers: {final_combined_df['is_refund_abuser'].sum()}\")\n",
    "\n",
    "# Display some statistics for the target variable\n",
    "print(\"\\n--- Distribution of 'is_refund_abuser' ---\")\n",
    "print(final_combined_df['is_refund_abuser'].value_counts())\n",
    "print(\"\\n--- Proportion of 'is_refund_abuser' ---\")\n",
    "print(final_combined_df['is_refund_abuser'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e970f0d-4c11-4d48-aa84-512ee9325b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Simulated_CustomerID</th>\n",
       "      <th>TotalUniqueOrders</th>\n",
       "      <th>TotalItemsPurchased</th>\n",
       "      <th>TotalItemsReturned</th>\n",
       "      <th>TotalPurchaseValue</th>\n",
       "      <th>TotalRefundValue</th>\n",
       "      <th>FirstTransactionDate</th>\n",
       "      <th>LastTransactionDate</th>\n",
       "      <th>RefundRate_by_Items</th>\n",
       "      <th>RefundRate_by_Value</th>\n",
       "      <th>AccountAgeDays</th>\n",
       "      <th>TotalTickets</th>\n",
       "      <th>Tickets_TypeRefundRequest</th>\n",
       "      <th>Tickets_TypeDeliveryIssue</th>\n",
       "      <th>Tickets_TypeProductInquiry</th>\n",
       "      <th>Tickets_KeywordRefundCount</th>\n",
       "      <th>Tickets_KeywordDamageCount</th>\n",
       "      <th>Tickets_KeywordMissingCount</th>\n",
       "      <th>AvgTicketSentimentScore</th>\n",
       "      <th>MinTicketSentimentScore</th>\n",
       "      <th>is_refund_abuser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>2</td>\n",
       "      <td>74215</td>\n",
       "      <td>74215</td>\n",
       "      <td>77183.60</td>\n",
       "      <td>77183.6</td>\n",
       "      <td>2011-01-18 10:01:00</td>\n",
       "      <td>2011-01-18 10:17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>7</td>\n",
       "      <td>2458</td>\n",
       "      <td>0</td>\n",
       "      <td>4310.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-12-07 14:57:00</td>\n",
       "      <td>2011-12-07 15:52:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12348</td>\n",
       "      <td>4</td>\n",
       "      <td>2341</td>\n",
       "      <td>0</td>\n",
       "      <td>1797.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-12-16 19:09:00</td>\n",
       "      <td>2011-09-25 13:13:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12349</td>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>0</td>\n",
       "      <td>1757.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-11-21 09:51:00</td>\n",
       "      <td>2011-11-21 09:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12350</td>\n",
       "      <td>1</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>334.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-02-02 16:01:00</td>\n",
       "      <td>2011-02-02 16:01:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Simulated_CustomerID  TotalUniqueOrders  TotalItemsPurchased  \\\n",
       "0                 12346                  2                74215   \n",
       "1                 12347                  7                 2458   \n",
       "2                 12348                  4                 2341   \n",
       "3                 12349                  1                  631   \n",
       "4                 12350                  1                  197   \n",
       "\n",
       "   TotalItemsReturned  TotalPurchaseValue  TotalRefundValue  \\\n",
       "0               74215            77183.60           77183.6   \n",
       "1                   0             4310.00               0.0   \n",
       "2                   0             1797.24               0.0   \n",
       "3                   0             1757.55               0.0   \n",
       "4                   0              334.40               0.0   \n",
       "\n",
       "  FirstTransactionDate LastTransactionDate  RefundRate_by_Items  \\\n",
       "0  2011-01-18 10:01:00 2011-01-18 10:17:00                  1.0   \n",
       "1  2010-12-07 14:57:00 2011-12-07 15:52:00                  0.0   \n",
       "2  2010-12-16 19:09:00 2011-09-25 13:13:00                  0.0   \n",
       "3  2011-11-21 09:51:00 2011-11-21 09:51:00                  0.0   \n",
       "4  2011-02-02 16:01:00 2011-02-02 16:01:00                  0.0   \n",
       "\n",
       "   RefundRate_by_Value  AccountAgeDays  TotalTickets  \\\n",
       "0                  1.0               0           0.0   \n",
       "1                  0.0             365           3.0   \n",
       "2                  0.0             282           3.0   \n",
       "3                  0.0               0           1.0   \n",
       "4                  0.0               0           2.0   \n",
       "\n",
       "   Tickets_TypeRefundRequest  Tickets_TypeDeliveryIssue  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        1.0                        0.0   \n",
       "2                        1.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        2.0                        0.0   \n",
       "\n",
       "   Tickets_TypeProductInquiry  Tickets_KeywordRefundCount  \\\n",
       "0                         0.0                         0.0   \n",
       "1                         1.0                         0.0   \n",
       "2                         0.0                         0.0   \n",
       "3                         0.0                         0.0   \n",
       "4                         0.0                         1.0   \n",
       "\n",
       "   Tickets_KeywordDamageCount  Tickets_KeywordMissingCount  \\\n",
       "0                         0.0                          0.0   \n",
       "1                         1.0                          0.0   \n",
       "2                         0.0                          0.0   \n",
       "3                         0.0                          0.0   \n",
       "4                         0.0                          0.0   \n",
       "\n",
       "   AvgTicketSentimentScore  MinTicketSentimentScore  is_refund_abuser  \n",
       "0                 0.000000                 0.000000                 0  \n",
       "1                -0.777778                -1.000000                 0  \n",
       "2                -1.000000                -1.000000                 0  \n",
       "3                -0.333333                -0.333333                 0  \n",
       "4                -1.000000                -1.000000                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "final_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d01ef019-b629-4300-8b83-08623f492799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4372, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afefc150-ebba-4ac5-ad6e-4f27faeacfab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
